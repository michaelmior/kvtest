\documentclass{sig-alternate-2013}

\pdfminorversion=4
\pdfimageresolution=600

\usepackage{caption}
\usepackage{subfig}
\usepackage{todonotes}
\usepackage[hidelinks]{hyperref}
\usepackage{fixltx2e}
\usepackage{enumitem}
\usepackage[english]{babel}
\usepackage{microtype}

\clubpenalty=10000
\widowpenalty=10000

\makeatletter
\def\@copyrightspace{\relax}
\makeatother

\begin{document}

\hypersetup{pdftitle=Congestion-Aware Join Optimization in Key-Value Stores}
\hypersetup{pdfauthor={Xu Cui, Michael Mior, and Xinan Yan}}

\title{Congestion-Aware Join Optimization in Key-Value Stores}

\numberofauthors{3}
\author{
    \alignauthor{
        Xu Cui\\
        \affaddr{University of Waterloo}\\
        \email{xcui@uwaterloo.ca}
    }
    \alignauthor{
        Michael Mior\\
        \affaddr{University of Waterloo}\\
        \email{mmior@uwaterloo.ca}
    }
    \alignauthor{
        Xinan Yan\\
        \affaddr{University of Waterloo}\\
        \email{x29yan@uwaterloo.ca}
    }
}

\maketitle

\begin{abstract}
Applications which use key-value stores to execute higher-level queries need to aggregate data from multiple nodes.
In the case where all data is contained in main memory, the bottleneck becomes the network transfer of values from the datastore to the application.
When some keys become highly popular, network links to machines hosting these keys can become saturated and affect application performance.
In addition, nodes will compete with each other for bandwidth and uninformed traffic prioritization can result in reduced query execution time.
We demonstrate an approach based on software-defined networking (SDN) that takes advantage of replication and network performance measurements to effectively route requests over underutilized links.
\end{abstract}

\section{Introduction}

Recent trends have shown a proliferation of databases termed ``NoSQL'' which frequently eschew traditional database concepts such as referential integrity and ACID transactions for the sake of performance.
However, applications using these databases still have a need to perform complex queries.
Especially in the case of analytical queries, this may force the application designer to implement constructs such as joins at the application level.
This requires a significant amount of data transfer between nodes.
Given that it is common for data to be held in memory for performance reasons, the bottleneck for this data transfer is pushed up to the network layer.

\begin{figure}
    \centering
    \missingfigure{Topology graph}
    \caption{Sample network topology}\label{fig:sample-topology}
\end{figure}

Poor network scheduling can easily result in suboptimal query execution.
For example, consider the simple topology shown in Figure~\ref{fig:sample-topology}.
Assume a query is being processed that requires data to be sent between hosts A and C and hosts B and D that together will use the full capacity of all links in the network.
If the flows have equal bandwidth requirements, then fair bandwidth allocation will perform well.
However, if the flow between A and C requires twice the bandwidth of the flow between B and D, the first flow will have a longer completion time while it waits for available bandwidth.

In this scenario, if we schedule traffic using weighted fair queuing and reserve additional bandwidth for the first flow, it will complete sooner.
This results in a longer completion time for the second flow, but if we assume the query depends on all flows to be completed, we can see an overall reduction in query time.
Similarly, in the face of replicated data, a network-aware query processing engine can select routes and replicas to maximize link utilization and improve performance.
This type of intelligent network behaviour is difficult to configure in a traditional network stack.
However, with the advent of SDN, it is possible for a smart SDN controller to make global decisions based on the knowledge of higher-level application queries.

\section{System Overview}

\subsection{Query Model}

\begin{figure}
    \centering
    \missingfigure{ER diagram}
    \caption{Simple query entities}\label{fig:entities}
\end{figure}

Our prototype system considers foreign key join queries between entity sets with a fixed join order and simple filtering on attributes of the first entity set.
For example, assume we have two entity sets \texttt{User} and \texttt{Item} with a one-to-many foreign key relating a user to each item as in Figure~\ref{fig:entities}.
A query (in SQL) syntax may look like \texttt{SELECT * FROM User, Item WHERE Item.User\_id = User.id AND Item.price > 20}.
In the future, we plan to consider a richer query language.
This will also present more interesting opportunities for optimization.

The execution model for these queries is very straightforward.
We consider the execution of the simple query given above.
We start by passing the query to each node which has entities of the class on the left side of the join (\texttt{Item}).
Those nodes will scan their local list of entities and apply the necessary filters (\texttt{price > 20}).
Each node then forwards the necessary foreign keys to nodes holding entites of the class on the right side of the join (\texttt{User}).
These nodes are then able to look up entities on the other side of the join and results can be passed back to the client.

\subsection{Architecture}

\subsection{Flow Scheduling}

Simple approaches to bandwith allocation such as max-min fairness pose significant problems in our settings.
If we were to use fair share allocation, then the node with the largest share of the query results, bottlenecked by available bandwidth, would become a straggler.
Nodes with a small share of query results could finish much more quickly only to wait for these stragglers.
To minimize the overall completion time of queries, we can allocate bandwidth to each node as the fraction of query results which will be returned by the node.
This will speed up stragglers at the expense of slowing down nodes with a smaller allocation.
However, the net result is a reduction in the average execution cost.

We currently deal with a read-only workload where the distribution of data is known by all nodes.
Each node is able to calculate the fraction of query results it will return.
A node can signal the expected fraction of the results for a query it will return by setting bits within the packet header.
When a new flow is issued for query processing, the controller can inspect these bits and assign an appropriate priority to each flow.

\section{Related Work}

The majority of work on query processing in key-value stores is in executing queries on data stored in distributed hash tables (DHTs) in peer-to-peer (P2P) networks.
For example, Harren et al.~\cite{Harren2002} propose a basic query model for executing complex queries in this scenario.
Their approach aims to minimize communication cost, but it is designed for P2P systems where the network is not under control of the application and is therefore unable to make use of network-aware techniques.
PIER~\cite{Huebsch2005} is a similar query processing engine over DHTs which is also not network-aware.
However, the query processing model used by PIER may be an interesting area to explore.

There has also been some work in exploiting software-defined networking for big data applications.
Wang et al.~\cite{Wang2012} examined network traffic patterns in a Hadoop cluster and identified opportunities to combine network-aware job scheduling with dynamic routing configuration to improve job completion time.
Xiong et al.~\cite{Xiong2014} examine the usefulness of software-defined networking in supporting distributed analytical queries.
Their workload consits of read-only SQL queries where query processing is bandwidth-intensive.
They construct a global query optimizer which decides on join order and how query results should be passed between sites.
This work takes a similar approach to ours, but also identifies many opportunities for further work.

\section{Evaluation}

We run all our experiments on a simulated network on a single machine using Mininet~\cite{Lantz2010}.
We use Open vSwitch~\cite{Pfaff2009} as our switch which supports queues with varying bandwidth guarantees.
Our controller uses the POX~\cite{Gude2008} platform and OpenFlow~\cite{McKeown2008} 1.0.

Queries use data taken from the RUBiS~\cite{Cecchet2002} benchmark, which is a Web application simulating an online auction.
We distribute data on users and the items they are selling between all nodes with no replication.

\section{Future Work}

There are many opportunities to combine this work with appropriate key placement strategies for further performance optimizations.
For heterogenous networks, a key placement strategy which is network and workload aware may provide significant performance advantages.
Our current query execution model is very simplistic and could be expanded to support richer queries and distributed index data structures.
We would also like to investigate other query types such as aggregation which we suspect would also benefit from our approach.
This presents new challenges in network scheduling, especially in the face of concurrent queries of multiple different types.

Our current system also does not deal with the possibility of updates or replication.
There is potential to further exploit SDN techniques by allowing low latency updates to data in the presence of the high bandwidth flows used for query processing.
Replication provides further opportunity for optimization as flows can be routed to multiple possible locations to avoid bottleneck links.

\section{Conclusion}

\let\theOLDbibliography\thebibliography\renewcommand{\thebibliography}[1]{\theOLDbibliography{#1}%
\item[]\vspace*{0.5mm}}

\bibliographystyle{abbrv}
{\scriptsize
\bibliography{paper}
}

\end{document}
